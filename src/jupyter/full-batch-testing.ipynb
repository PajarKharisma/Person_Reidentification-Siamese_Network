{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import torch\n",
    "import torchvision.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import src.neuralNetworksArch.BstCnn as bst\n",
    "import src.neuralNetworksArch.Mpkp as mpkp\n",
    "\n",
    "import src.dataPreparation.CreatePartial as create_partial\n",
    "import src.utils.Visual as vis\n",
    "import src.utils.Checkpoint as ckp\n",
    "import src.utils.Metrics as metrics\n",
    "\n",
    "from src.config.Param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '../../models/FULL - BST - CUHK02.pth'\n",
    "PATH = '../../dataset/testing/diff_cam/'\n",
    "DATATEST_PATH = PATH + 'testing.csv'\n",
    "IMAGES_PATH = PATH + '/images/full/'\n",
    "IMAGES_OCCL_PATH = PATH + '/images/occl_60/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_image2tensor(img, convert=True):\n",
    "    if convert:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:, :, ::-1].transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).float() / 255.0\n",
    "    img = [img]\n",
    "    img_tensors = torch.stack(img)\n",
    "\n",
    "    return img_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = {}\n",
    "model_arch  = bst.BstCnn()\n",
    "checkpoint = ckp.load_checkpoint(load_dir=MODEL_PATH)\n",
    "model_arch.load_state_dict(checkpoint['state_dict'])\n",
    "model_arch.eval()\n",
    "\n",
    "model['model'] = model_arch\n",
    "model['min_dist'] = checkpoint['dist'][0]\n",
    "model['max_dist'] = checkpoint['dist'][1]\n",
    "# model['threshold'] = checkpoint['threshold'] + 0.1\n",
    "model['threshold'] = 0.5\n",
    "model['threshold_list'] = checkpoint['threshold_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATATEST_PATH)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "verbose = False\n",
    "with torch.no_grad():\n",
    "    for index, data in df.iterrows():\n",
    "        if verbose == True:\n",
    "            print('No-{}'.format(index+1))\n",
    "            print('-'*50)\n",
    "        img1 = cv2.imread(IMAGES_PATH + data['image_1'])\n",
    "        img2 = cv2.imread(IMAGES_OCCL_PATH + data['image_2'])\n",
    "        label = data['label']\n",
    "        \n",
    "        input1 = cv_image2tensor(img1)\n",
    "        input2 = cv_image2tensor(img2)\n",
    "        out1, out2 = model['model'](input1, input2)\n",
    "        euclidean_distance = F.pairwise_distance(out1, out2)\n",
    "\n",
    "#         dist = metrics.normalize_data(euclidean_distance.item(), model['max_dist'])\n",
    "        dist = 1 - (1 / (1 + euclidean_distance.item()))\n",
    "        pred = 0.0 if dist <= model['threshold'] else 1.0\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(float(label))\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('actual distance => {}'.format(dist))\n",
    "            print('actual thresh => {}'.format(model['threshold']))\n",
    "            print('actual label => {}'.format(label))\n",
    "        \n",
    "        if verbose == True:\n",
    "            concatenated = torch.cat((cv_image2tensor(img1, False), cv_image2tensor(img2, False)),0)\n",
    "            vis.imshow(torchvision.utils.make_grid(concatenated))\n",
    "            print('='*50, end='\\n\\n')\n",
    "\n",
    "acc = accuracy_score(np.array(y_true), np.array(y_pred))\n",
    "print('Accuracy : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464biteb93521d834e45aeaba8e45a84cf6735"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
