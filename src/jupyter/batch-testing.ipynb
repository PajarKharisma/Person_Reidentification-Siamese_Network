{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import torch\n",
    "import torchvision.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import src.dataPreparation.CreatePartial as create_partial\n",
    "import src.neuralNetworksArch.BstCnn as bst\n",
    "import src.utils.Visual as vis\n",
    "import src.utils.Checkpoint as ckp\n",
    "import src.utils.Metrics as metrics\n",
    "\n",
    "from src.config.Param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = [\n",
    "    '../../models/PARTIAL_1 #1 - CUHK03.pth',\n",
    "    '../../models/PARTIAL_1 #2 - CUHK03.pth',\n",
    "    '../../models/PARTIAL_1 #3 - CUHK03.pth'\n",
    "]\n",
    "DATATEST_PATH = '../../dataset/testing/same_cam/testing.csv'\n",
    "IMAGES_PATH = '../../dataset/testing/same_cam/images/full/'\n",
    "IMAGES_OCCL_PATH = '../../dataset/testing/same_cam/images/occl_20/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_image2tensor(img, convert=True):\n",
    "    if convert:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:, :, ::-1].transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).float() / 255.0\n",
    "    img = [img]\n",
    "    img_tensors = torch.stack(img)\n",
    "\n",
    "    return img_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BstCnn2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BstCnn2, self).__init__()\n",
    "\n",
    "        self.conv5x5_1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(2),\n",
    "            nn.Conv2d(3, 16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv3x3_1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(3, 16, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv3x3_2 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(35, 16, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv1x1_2 = nn.Sequential(\n",
    "            nn.Conv2d(35, 16, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv1x1_3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((8, 8)) # partial images\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*8*8, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        out_5x5 = self.conv5x5_1(x)\n",
    "        out_3x3 = self.conv3x3_1(x)\n",
    "        output = torch.cat([out_5x5, out_3x3, x], 1)\n",
    "        output = self.maxpool(output)\n",
    "        \n",
    "        out_3x3 = self.conv3x3_2(output)\n",
    "        out_1x1 = self.conv1x1_2(output)\n",
    "        output = torch.cat([out_3x3, out_1x1], 1)\n",
    "        output = self.maxpool(output)\n",
    "\n",
    "        out_1x1 = self.conv1x1_3(output)\n",
    "        output = self.avgpool(out_1x1)\n",
    "\n",
    "        output = output.reshape(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2, input3=None):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        if input3 == None:\n",
    "            return output1, output2\n",
    "        else:\n",
    "            output3 = self.forward_once(input3)\n",
    "            return output1, output2, output3\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for index, path in enumerate(MODEL_PATH):\n",
    "    data = {}\n",
    "    if index != 2:\n",
    "        model  = bst.BstCnn()\n",
    "    else:\n",
    "        model = BstCnn2()\n",
    "    checkpoint = ckp.load_checkpoint(load_dir=path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    data['id'] = 'PART-' + str(index+1)\n",
    "    data['model'] = model\n",
    "    data['min_dist'] = checkpoint['dist'][0]\n",
    "    data['max_dist'] = checkpoint['dist'][1]\n",
    "#     data['threshold'] = checkpoint['threshold']\n",
    "    data['threshold'] = 0.3\n",
    "    data['threshold_list'] = checkpoint['threshold_list']\n",
    "    models.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : 151805\n",
      "b : 99420\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "for i in models[1]['threshold_list']:\n",
    "    if i == 0.15000000000000002:\n",
    "        a +=1\n",
    "    elif i == 0.20000000000000004:\n",
    "        b += 1\n",
    "        \n",
    "print('a : {}'.format(a))\n",
    "print('b : {}'.format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "Accuracy : 0.64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATATEST_PATH)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "verbose = False\n",
    "with torch.no_grad():\n",
    "    for index, data in df.iterrows():\n",
    "#         if index != 47:\n",
    "#             continue\n",
    "        if verbose == True:\n",
    "            print('No-{}'.format(index+1))\n",
    "            print('-'*50)\n",
    "        img1 = cv2.imread(IMAGES_PATH + data['image_1'])\n",
    "        img2 = cv2.imread(IMAGES_OCCL_PATH + data['image_2'])\n",
    "        label = data['label']\n",
    "\n",
    "        img1_part = list(create_partial.partial_image_1(img1))\n",
    "        img2_part = list(create_partial.partial_image_1(img2))\n",
    "\n",
    "        thresholds = []\n",
    "        dists = []\n",
    "        for i, (input1, input2, model) in enumerate(zip(img1_part, img2_part, models)):\n",
    "            input1 = cv_image2tensor(input1)\n",
    "            input2 = cv_image2tensor(input2)\n",
    "            out1, out2 = model['model'](input1, input2)\n",
    "            euclidean_distance = F.pairwise_distance(out1, out2)\n",
    "            \n",
    "            dist = metrics.normalize_data(euclidean_distance.item(), model['max_dist'])\n",
    "            dists.append(dist)\n",
    "            thresholds.append(model['threshold'])\n",
    "            \n",
    "            if verbose == True:\n",
    "                print('PART-{} DISTANCE => {}'.format((i+1), dist))\n",
    "                print('Threshold => {}'.format(model['threshold']))\n",
    "                print('-'*50)\n",
    "            \n",
    "        cat_dist, cat_thresh = metrics.concatenate(dists, thresholds, [0.2, 0.6, 0.2])\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('actual distance => {}'.format(cat_dist))\n",
    "            print('actual thresh => {}'.format(cat_thresh))\n",
    "            print('actual label => {}'.format(label))\n",
    "        \n",
    "        y_true.append(float(label))\n",
    "        pred = 0.0 if cat_dist <= cat_thresh else 1.0\n",
    "        y_pred.append(pred)\n",
    "        concatenated = torch.cat((cv_image2tensor(img1, False), cv_image2tensor(img2, False)),0)\n",
    "        \n",
    "        if verbose == True:\n",
    "            vis.imshow(torchvision.utils.make_grid(concatenated))\n",
    "            print('='*50, end='\\n\\n')\n",
    "\n",
    "print(len([i==0.0 for i in y_pred]))\n",
    "print(len([i==1.0 for i in y_pred]))\n",
    "acc = accuracy_score(np.array(y_true), np.array(y_pred))\n",
    "print('Accuracy : {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t, p in zip(y_true, y_pred):\n",
    "#     print('True : {}'.format(t))\n",
    "#     print('Predict : {}'.format(p))\n",
    "#     print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464biteb93521d834e45aeaba8e45a84cf6735"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
