{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import torch\n",
    "import torchvision.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import src.dataPreparation.CreatePartial as create_partial\n",
    "import src.neuralNetworksArch.BstCnn as bst\n",
    "import src.utils.Visual as vis\n",
    "import src.utils.Checkpoint as ckp\n",
    "import src.utils.Metrics as metrics\n",
    "\n",
    "from src.config.Param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = [\n",
    "    '../../models/PARTIAL_3 #1.pth',\n",
    "    '../../models/PARTIAL_3 #2.pth',\n",
    "    '../../models/PARTIAL_3 #3.pth',\n",
    "    '../../models/PARTIAL_3 #4.pth'\n",
    "]\n",
    "PATH = '../../dataset/testing/same_cam/'\n",
    "DATATEST_PATH = PATH + 'testing.csv'\n",
    "IMAGES_PATH = PATH + '/images/full/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_image2tensor(img, convert=True):\n",
    "    if convert:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:, :, ::-1].transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).float() / 255.0\n",
    "    img = [img]\n",
    "    img_tensors = torch.stack(img)\n",
    "\n",
    "    return img_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for index, path in enumerate(MODEL_PATH):\n",
    "    data = {}\n",
    "    model  = bst.BstCnn()\n",
    "    checkpoint = ckp.load_checkpoint(load_dir=path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    data['id'] = 'PART-' + str(index+1)\n",
    "    data['model'] = model\n",
    "    data['min_dist'] = checkpoint['dist'][0]\n",
    "    data['max_dist'] = checkpoint['dist'][1]\n",
    "    data['threshold'] = checkpoint['threshold'] + 0.1\n",
    "#     data['threshold'] = checkpoint['threshold']\n",
    "    data['threshold_list'] = checkpoint['threshold_list']\n",
    "    models.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Part-1: 0.826797385620915\n",
      "Accuracy Part-2: 0.803921568627451\n",
      "Accuracy Part-3: 0.7549019607843137\n",
      "Accuracy Part-4: 0.7189542483660131\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATATEST_PATH)\n",
    "y_true = []\n",
    "y_pred = [[],[],[],[]]\n",
    "\n",
    "verbose = False\n",
    "with torch.no_grad():\n",
    "    for index, data in df.iterrows():\n",
    "        if verbose == True:\n",
    "            print('No-{}'.format(index+1))\n",
    "            print('-'*50)\n",
    "        img1 = cv2.imread(IMAGES_PATH + data['image_1'])\n",
    "        img2 = cv2.imread(IMAGES_PATH + data['image_2'])\n",
    "        label = data['label']\n",
    "\n",
    "        img1_part = list(create_partial.partial_image_3(img1))\n",
    "        img2_part = list(create_partial.partial_image_3(img2))\n",
    "\n",
    "        for i, (input1, input2, model) in enumerate(zip(img1_part, img2_part, models)):\n",
    "            input1 = cv_image2tensor(input1, False)\n",
    "            input2 = cv_image2tensor(input2, False)\n",
    "            out1, out2 = model['model'](input1, input2)\n",
    "            euclidean_distance = F.pairwise_distance(out1, out2)\n",
    "            \n",
    "            dist = metrics.normalize_data(euclidean_distance.item(), model['max_dist'])\n",
    "            pred = 0.0 if dist <= model['threshold'] else 1.0\n",
    "            y_pred[i].append(pred)\n",
    "            \n",
    "            if verbose == True:\n",
    "                print('PART-{} DISTANCE => {}'.format((i+1), dist))\n",
    "                print('Threshold => {}'.format(model['threshold']))\n",
    "                print('-'*50)\n",
    "        \n",
    "        y_true.append(float(label))\n",
    "        concatenated = torch.cat((cv_image2tensor(img1, False), cv_image2tensor(img2, False)),0)\n",
    "        \n",
    "        if verbose == True:\n",
    "            vis.imshow(torchvision.utils.make_grid(concatenated))\n",
    "            print('='*50, end='\\n\\n')\n",
    "\n",
    "for index, pred in enumerate(y_pred):\n",
    "    acc = accuracy_score(np.array(y_true), np.array(pred))\n",
    "    print('Accuracy Part-{}: {}'.format(index+1, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464biteb93521d834e45aeaba8e45a84cf6735"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
